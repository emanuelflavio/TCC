
\chapter{Resultados e Discursões}\label{resultados}

Nesta seção, são apresentados todos os dados e resultados obtidos ao longo dos experimentos. Primeiro, descrevem-se as métricas de avaliação dos modelos de classificação individuais utilizados no estudo. Em seguida, são exibidas as métricas dos ensembles construídos por meio das diferentes estratégias de seleção. Por fim, são realizadas comparações entre os modelos e discutidos os resultados observados, destacando o impacto das técnicas aplicadas no desempenho final.  

\section{Desempenhos dos modelos individuais}

Foram avaliados dez modelos de classificação em quatro cenários distintos: Letterboxd com pré-processamento, Letterboxd sem pré-processamento, IMDb sem pré-processamento e IMDb com pré-processamento.

Nos resultados obtidos, já podemos perceber as diferenças de desempenho entre os modelos e o impacto do pré-processamento sobre a eficácia dos algoritmos.

As tabelas a seguir detalham os resultados obtidos para cada cenário, apresentando as métricas de avaliação: Precisão, Recall e F1-Score para as classes Negativa e Positiva.

\begin{table}[H]
	\centering
	\caption{Métricas dos Modelos Individuais(Letterborxd - Com Pré-Processamento	)}
	\resizebox{\textwidth}{!}{
		\begin{tabular}{lcccccc}
			\toprule
			\multirow{2}{*}{\textbf{Modelo}} & \multicolumn{3}{c}{\textbf{Classe Negativa}} & \multicolumn{3}{c}{\textbf{Classe Positiva}} \\
			\cmidrule(lr){2-4} \cmidrule(lr){5-7}
			& \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} \\
			\midrule
			K-Nearest Neighbors & 0.54 & 0.75 & 0.63 & 0.67 & 0.43 & 0.52 \\
			Naive Bayes & 0.79 & 0.78 & 0.78 & 0.81 & 0.82 & 0.81 \\
			Regressão Logística & 0.80 & 0.79 & 0.80 & 0.82 & 0.83 & 0.82 \\
			SGD & 0.80 & 0.80 & 0.80 & 0.82 & 0.82 & 0.82 \\
			SVM Linear & 0.80 & 0.79 & 0.80 & 0.82 & 0.83 & 0.82 \\
			Random Forest & 0.78 & 0.69 & 0.73 & 0.75 & 0.83 & 0.79 \\
			LightGBM & 0.77 & 0.80 & 0.78 & 0.81 & 0.79 & 0.80 \\
			AdaBoost & 0.74 & 0.81 & 0.77 & 0.81 & 0.75 & 0.78 \\
			Multi-Layer Perceptron & 0.77 & 0.81 & 0.79 & 0.82 & 0.79 & 0.80 \\
			Decision Tree & 0.60 & 0.84 & 0.70 & 0.78 & 0.49 & 0.61 \\
			\bottomrule
		\end{tabular}%
	}
\end{table}

No cenário da base Letterboxd com pré-processamento, pode-se observar que os \textit{modelos lineares} apresentaram métricas melhores que os de outro tipo. Os modelos \textit{SVM Linear}, \textit{Regressão Logística} e \textit{SGD} apresentaram F1-Scores entre \textit{0.80} e \textit{0.82}, tanto para a classe positiva quanto para a negativa. Quanto aos modelos que não tiveram uma boa performance, destacam-se \textit{KNN} e a \textit{Decision Tree}, com F1-Scores entre \textit{0.52} e \textit{0.70}.

\begin{table}[H]
	\centering
	\caption{Métricas dos Modelos Individuais(Letterboxd - Sem Pré-Processamento)}
	\resizebox{\textwidth}{!}{
		\begin{tabular}{lcccccc}
			\toprule
			\multirow{2}{*}{\textbf{Modelo}} & \multicolumn{3}{c}{\textbf{Classe Negativa}} & \multicolumn{3}{c}{\textbf{Classe Positiva}} \\
			\cmidrule(lr){2-4} \cmidrule(lr){5-7}
			& \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} \\
			\midrule
			Naive Bayes & 0.79 & 0.77 & 0.78 & 0.80 & 0.82 & 0.81 \\
			Regressão Logística & 0.80 & 0.79 & 0.79 & 0.82 & 0.82 & 0.82 \\
			SVM Linear & 0.80 & 0.80 & 0.80 & 0.82 & 0.82 & 0.82 \\
			Random Forest & 0.79 & 0.66 & 0.72 & 0.74 & 0.84 & 0.79 \\
			K-Nearest Neighbors & 0.56 & 0.71 & 0.62 & 0.66 & 0.50 & 0.57 \\
			Multi-Layer Perceptron & 0.77 & 0.78 & 0.78 & 0.81 & 0.79 & 0.80 \\
			Decision Tree & 0.71 & 0.42 & 0.53 & 0.63 & 0.85 & 0.72 \\
			LightGBM & 0.77 & 0.80 & 0.79 & 0.82 & 0.79 & 0.81 \\
			AdaBoost & 0.74 & 0.79 & 0.77 & 0.80 & 0.76 & 0.78 \\
			SGD & 0.79 & 0.80 & 0.80 & 0.82 & 0.81 & 0.82 \\
			\bottomrule
		\end{tabular}%
	}
\end{table}

No da base Letterboxd sem pré-processamento, pode-se observar melhorias nos resultados. Os modelos lineares ainda foram superiores, com F1-Scores próximos a \textit{0.82}. Isso sugere que o pré-processamento aplicado pode ter removido informações relevantes do texto, ou seja, a remoção de palavras neste caso prejudicou o desempenho do modelo. Os modelos \textit{KNN} e \textit{Decision Tree} ainda tiveram um desempenho abaixo, e os demais foram intermediários.


\begin{table}[H]
	\centering
	\caption{Métricas dos Modelos Individuais(IMDB - Com Pré-Processamento)}
	\resizebox{\textwidth}{!}{
		\begin{tabular}{lcccccc}
			\toprule
			\multirow{2}{*}{\textbf{Modelo}} & \multicolumn{3}{c}{\textbf{Classe Negativa}} & \multicolumn{3}{c}{\textbf{Classe Positiva}} \\
			\cmidrule(lr){2-4} \cmidrule(lr){5-7}
			& \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} \\
			\midrule
			Naive Bayes & 0.87 & 0.83 & 0.85 & 0.84 & 0.88 & 0.86 \\
			Regressão Logística & 0.90 & 0.88 & 0.89 & 0.88 & 0.90 & 0.89 \\
			SVM Linear & 0.91 & 0.88 & 0.89 & 0.88 & 0.91 & 0.89 \\
			Random Forest & 0.87 & 0.82 & 0.84 & 0.83 & 0.87 & 0.85 \\
			K-Nearest Neighbors & 0.78 & 0.63 & 0.70 & 0.69 & 0.82 & 0.75 \\
			Multi-Layer Perceptron & 0.88 & 0.88 & 0.88 & 0.88 & 0.88 & 0.88 \\
			Decision Tree & 0.76 & 0.66 & 0.71 & 0.70 & 0.79 & 0.74 \\
			LightGBM & 0.88 & 0.85 & 0.86 & 0.85 & 0.89 & 0.87 \\
			AdaBoost & 0.86 & 0.83 & 0.85 & 0.84 & 0.87 & 0.85 \\
			SGD & 0.88 & 0.88 & 0.88 & 0.88 & 0.88 & 0.88 \\
			\bottomrule
		\end{tabular}%
	}
\end{table}

Na base do IMDb sem pré-processamento, que é uma base mais estruturada, os modelos apresentaram desempenhos significativamente melhores. No entanto, os modelos lineares ainda foram superiores: \textit{SVM Linear}, \textit{Regressão Logística} e \textit{SGD} obtiveram um F1-Score de aproximadamente \textit{0.89}. Isso pode ser explicado pela qualidade da base de dados, que tem menos ruído. Os modelos \textit{KNN} e \textit{Decision Tree} continuaram sendo os piores, com F1-Scores na faixa dos \textit{0.70}.

\begin{table}[H]
	\centering
	\caption{Métricas dos Modelos Individuais(IMDB - Sem Pré-Processamento)}
	\resizebox{\textwidth}{!}{
		\begin{tabular}{lcccccc}
			\toprule
			\multirow{2}{*}{\textbf{Modelo}} & \multicolumn{3}{c}{\textbf{Classe Negativa}} & \multicolumn{3}{c}{\textbf{Classe Positiva}} \\
			\cmidrule(lr){2-4} \cmidrule(lr){5-7}
			& \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} \\
			\midrule
			Naive Bayes & 0.87 & 0.84 & 0.86 & 0.84 & 0.88 & 0.86 \\
			Regressão Logística & 0.90 & 0.88 & 0.89 & 0.88 & 0.91 & 0.89 \\
			SVM Linear & 0.90 & 0.88 & 0.89 & 0.88 & 0.91 & 0.89 \\
			Random Forest & 0.87 & 0.81 & 0.84 & 0.82 & 0.88 & 0.85 \\
			K-Nearest Neighbors & 0.74 & 0.69 & 0.71 & 0.71 & 0.75 & 0.73 \\
			Multi-Layer Perceptron & 0.88 & 0.86 & 0.87 & 0.86 & 0.88 & 0.87 \\
			Decision Tree & 0.79 & 0.64 & 0.71 & 0.70 & 0.83 & 0.76 \\
			LightGBM & 0.88 & 0.84 & 0.86 & 0.85 & 0.89 & 0.87 \\
			AdaBoost & 0.87 & 0.84 & 0.86 & 0.85 & 0.88 & 0.86 \\
			SGD & 0.91 & 0.86 & 0.89 & 0.87 & 0.92 & 0.89 \\
			\bottomrule
		\end{tabular}%
	}
\end{table}

Por fim, na base do IMDb com pré-processamento, pode-se observar que as métricas dos melhores modelos foram praticamente idênticas às do cenário sem pré-processamento. Isso indica que a base do IMDb já é bem estruturada e suficientemente limpa para que o pré-processamento adicional não traga benefícios e nem prejudique. Os mesmos modelos foram superiores (\textit{SVM Linear}, \textit{Regressão Logística} e \textit{SGD}), com valores entre \textit{0.88} e \textit{0.89}, enquanto o \textit{KNN} e a \textit{Decision Tree} ainda foram os menos eficazes.

Em resumo, os resultados demonstram que \textit{classificadores lineares} (\textit{SVM Linear}, \textit{Regressão Logística} e \textit{SGD}) são os mais adequados para a tarefa de análise de sentimento utilizando a representação \textit{TF-IDF}, mostrando eficácia superior tanto em bases menores (Letterboxd) quanto em bases maiores e mais estruturadas (IMDb).

Os modelos \textit{KNN} e \textit{Decision Tree} apresentaram um desempenho consistentemente inferior em todos os cenários. Contudo, seu uso foi relevante ao contribuir com a \textit{diversidade de métodos} nos esquemas de \textit{ensemble}.

Já os modelos baseados em árvores (\textit{Random Forest}, \textit{LightGBM} e \textit{AdaBoost}) exibiram um desempenho intermediário, porém satisfatório, posicionando-se como opções robustas.

Tais achados reforçam o que é estabelecido na literatura: \textit{modelos lineares são frequentemente superiores} quando se trata de classificação textual com TF-IDF. Além disso, a análise evidenciou o \textit{impacto variável do pré-processamento} em diferentes bases, podendo prejudicar, melhorar ou não ter efeito, dependendo da base.


porem



\section{DESEMPENHO DOS ENSEMBLES SEM SELEÇÃO}

Uma das etapas dos experimentos foi a avaliação do ensemble sem seleção, com o objetivo de observar o comportamento e como a \textit{diversidade de modelos} impacta a performance do ensemble tanto no \textit{Voting} quanto no \textit{Stacking}.

\begin{table}[H]
	\centering
	\caption{Métricas para Ensembles com 10 Modelos Base(Letterboxd - Com Pré-Processamento)}
	\begin{tabular}{lcccccc}
		\toprule
		\multirow{2}{*}{\textbf{Modelo}} & \multicolumn{3}{c}{\textbf{Classe Negativa}} & \multicolumn{3}{c}{\textbf{Classe Positiva}} \\
		\cmidrule(lr){2-4} \cmidrule(lr){5-7}
		& \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} \\
		\midrule
		Voting & 0.77 & 0.83 & 0.80 & 0.84 & 0.78 & 0.81 \\
		Stacking & 0.80 & 0.81 & 0.81 & 0.83 & 0.82 & 0.83 \\
		\bottomrule
	\end{tabular}
\end{table}

Na base \textit{Letterboxd com pré-processamento}, os resultados mostraram que o \textit{Stacking} obteve um desempenho superior, conseguindo atingir um F1-Score de \textit{0.81} e \textit{0.83} nas duas classes, enquanto o \textit{Voting} obteve valores de \textit{0.80} e \textit{0.81}. O Stacking foi capaz de aproveitar melhor essa diferença entre os modelos.

\begin{table}[H]
	\centering
	\caption{Métricas para Ensembles com 10 Modelos Base(Letterboxd - Sem Pré-Processamento)}
	\begin{tabular}{lcccccc}
		\toprule
		\multirow{2}{*}{\textbf{Modelo}} & \multicolumn{3}{c}{\textbf{Classe Negativa}} & \multicolumn{3}{c}{\textbf{Classe Positiva}} \\
		\cmidrule(lr){2-4} \cmidrule(lr){5-7}
		& \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} \\
		\midrule
		Voting & 0.79 & 0.81 & 0.80 & 0.83 & 0.81 & 0.82 \\
		Stacking & 0.80 & 0.80 & 0.80 & 0.82 & 0.82 & 0.82 \\
		\bottomrule
	\end{tabular}
\end{table}

Na versão \textit{sem pré-processamento} da Letterboxd, ambos os ensembles obtiveram desempenho semelhante, com F1-Scores entre \textit{0.80} e \textit{0.82}. O Stacking ainda apresentou um leve ganho na classe positiva, mas a diferença geral foi menor do que a observada no cenário com pré-processamento.

\begin{table}[ht]
	\centering
	\caption{Métricas para Ensembles com 10 Modelos Base(IMDb - Sem Pré-Processamento)}
	\begin{tabular}{lcccccc}
		\toprule
		\multirow{2}{*}{\textbf{Modelo}} & \multicolumn{3}{c}{\textbf{Classe Negativa}} & \multicolumn{3}{c}{\textbf{Classe Positiva}} \\
		\cmidrule(lr){2-4} \cmidrule(lr){5-7}
		& \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} \\
		\midrule
		Voting & 0.89 & 0.90 & 0.90 & 0.90 & 0.89 & 0.90 \\
		Stacking & 0.90 & 0.89 & 0.90 & 0.90 & 0.90 & 0.90 \\
		\bottomrule
	\end{tabular}
\end{table}


Na base \textit{IMDb sem pré-processamento}, os ensembles atingiram ótimos resultados. Tanto o \textit{Voting} quanto o \textit{Stacking} alcançaram F1-Scores próximos de \textit{0.90}. O Stacking ainda apresentou um leve ganho, mas, na prática, ambos os métodos tiveram desempenho muito similar.
 

\begin{table}[H]
	\centering
	\caption{Métricas dos Ensembles com 10 Modelos Base(IMDb - Com Pré-Processamento)}
	\begin{tabular}{lcccccc}
		\toprule
		\multirow{2}{*}{\textbf{Modelo}} & \multicolumn{3}{c}{\textbf{Classe Negativa}} & \multicolumn{3}{c}{\textbf{Classe Positiva}} \\
		\cmidrule(lr){2-4} \cmidrule(lr){5-7}
		& \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} \\
		\midrule
		Voting & 0.90 & 0.90 & 0.90 & 0.90 & 0.90 & 0.90 \\
		Stacking & 0.90 & 0.90 & 0.90 & 0.90 & 0.90 & 0.90 \\
		\bottomrule
	\end{tabular}
\end{table}

Para finalizar, na base do \textit{IMDb com pré-processamento}, os resultados foram bem parecidos com os do cenário sem pré-processamento, porém houve um leve ganho tanto no Voting quanto no Stacking. Com isso, confirma-se que o desempenho na base IMDb \textit{não é fortemente influenciado pelo pré-processamento}, e ensembles de grande porte podem ser \textit{robustos} mesmo com variações no tratamento do texto.

Os resultados mostraram que \textit{ensembles} com 10 modelos apresentam um desempenho bastante sólido em diversos cenários. Quando há ruído, o \textit{stacking} tende a ser superior ao \textit{voting}, enquanto o \textit{voting} já tem um bom desempenho quando os modelos base são mais consistentes.

\section{SELEÇÃO POR ACURÁCIA}
Nesta seção, serão mostrados os resultados dos \textit{ensembles} construídos por meio da seleção por acurácia (\textit{SA}), onde somente os modelos individuais com o maior desempenho são escolhidos para a composição do \textit{ensemble}. Aqui, os \textit{ensembles} serão formados por subconjuntos contendo 2, 3, 4 ou 5 modelos. Essa estratégia busca avaliar \textit{ensembles} de diferentes tamanhos.

As tabelas a seguir mostram os valores das acuracias de cada modelo que foram usadas como base para a formação dos ensembles:
\begin{table}[H]
	\centering
	\caption{Acurácia dos Modelos Individuais (LETTER - Sem Pré-Processamento)}
	\begin{tabular}{lc}
		\toprule
		\textbf{Modelo} & \textbf{Acurácia} \\
		\midrule
		Naive Bayes & 0.7950 \\
		Regressão Logística & 0.8076 \\
		SVM Linear & 0.8101 \\
		Random Forest & 0.7577 \\
		K-Nearest Neighbors & 0.5971 \\
		Multi-Layer Perceptron & 0.7882 \\
		Decision Tree & 0.6497 \\
		LightGBM & 0.7967 \\
		AdaBoost & 0.7744 \\
		SGD & 0.8078 \\
		\bottomrule
	\end{tabular}
\end{table}




\begin{table}[H]
	\centering
	\caption{Acurácia dos Modelos Individuais (LETTER - Com Pré-Processamento)}
	\begin{tabular}{lc}
		\toprule
		\textbf{Modelo} & \textbf{Acurácia} \\
		\midrule
		Naive Bayes & 0.7981 \\
		Regressão Logística & 0.8118 \\
		SVM Linear & 0.8107 \\
		Random Forest & 0.7645 \\
		K-Nearest Neighbors & 0.5833 \\
		Multi-Layer Perceptron & 0.7972 \\
		Decision Tree & 0.6583 \\
		LightGBM & 0.7916 \\
		AdaBoost & 0.7769 \\
		SGD & 0.8099 \\
		\bottomrule
	\end{tabular}
\end{table}



\begin{table}[H]
	\centering
	\caption{Acurácia dos Modelos Individuais (IMDB - Sem Pré-Processamento)}
	\begin{tabular}{lc}
		\toprule
		\textbf{Modelo} & \textbf{Acurácia} \\
		\midrule
		Naive Bayes & 0.8584 \\
		Regressão Logística & 0.8924 \\
		SVM Linear & 0.8930 \\
		Random Forest & 0.8426 \\
		K-Nearest Neighbors & 0.7226 \\
		Multi-Layer Perceptron & 0.8694 \\
		Decision Tree & 0.7330 \\
		LightGBM & 0.8634 \\
		AdaBoost & 0.8616 \\
		SGD & 0.8894 \\
		\bottomrule
	\end{tabular}
\end{table}



\begin{table}[H]
	\centering
	\caption{Acurácia dos Modelos Individuais (IMDB - Com Pré-Processamento)}
	\begin{tabular}{lc}
		\toprule
		\textbf{Modelo} & \textbf{Acurácia} \\
		\midrule
		Naive Bayes & 0.8538 \\
		Regressão Logística & 0.8902 \\
		SVM Linear & 0.8930 \\
		Random Forest & 0.8466 \\
		K-Nearest Neighbors & 0.7286 \\
		Multi-Layer Perceptron & 0.8784 \\
		Decision Tree & 0.7274 \\
		LightGBM & 0.8658 \\
		AdaBoost & 0.8510 \\
		SGD & 0.8816 \\
		\bottomrule
	\end{tabular}
\end{table}

 

\subsection{DESEMPENHO DOS ENSEMBLES COM 2 MODELOS}

\begin{table}[H]
	\centering
	\caption{Métricas para Ensembles SA 2 modelos: Regressão Logística, SVM Linear (Letterboxd - Com Pré-Processamento)}
	\begin{tabular}{lcccccc}
		\toprule
		\multirow{2}{*}{\textbf{Modelo}} & \multicolumn{3}{c}{\textbf{Classe Negativa}} & \multicolumn{3}{c}{\textbf{Classe Positiva}} \\
		\cmidrule(lr){2-4} \cmidrule(lr){5-7}
		& \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} \\
		\midrule
		Voting & 0.79 & 0.80 & 0.80 & 0.83 & 0.82 & 0.82 \\
		Stacking & 0.80 & 0.80 & 0.80 & 0.82 & 0.82 & 0.82 \\
		\bottomrule
	\end{tabular}
\end{table}

\begin{table}[H]
	\centering
	\caption{Métricas para Ensembles SA 2 modelos: SVM Linear e SGD (Letterboxd - Sem Pré-Processamento)}
	\begin{tabular}{lcccccc}
		\toprule
		\multirow{2}{*}{\textbf{Modelo}} & \multicolumn{3}{c}{\textbf{Classe Negativa}} & \multicolumn{3}{c}{\textbf{Classe Positiva}} \\
		\cmidrule(lr){2-4} \cmidrule(lr){5-7}
		& \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} \\
		\midrule
		Voting & 0.78 & 0.81 & 0.80 & 0.83 & 0.80 & 0.82 \\
		Stacking & 0.79 & 0.80 & 0.79 & 0.82 & 0.81 & 0.82 \\
		\bottomrule
	\end{tabular}
\end{table}


\begin{table}[H]
	\centering
	\caption{Métricas para Ensembles SA 2 modelos: SVM Linear e Regressão Logística (IMDb - Sem Pré-Processamento)}
	\begin{tabular}{lcccccc}
		\toprule
		\multirow{2}{*}{\textbf{Modelo}} & \multicolumn{3}{c}{\textbf{Classe Negativa}} & \multicolumn{3}{c}{\textbf{Classe Positiva}} \\
		\cmidrule(lr){2-4} \cmidrule(lr){5-7}
		& \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} \\
		\midrule
		Voting & 0.89 & 0.90 & 0.90 & 0.90 & 0.89 & 0.89 \\
		Stacking & 0.89 & 0.90 & 0.90 & 0.90 & 0.89 & 0.89 \\
		\bottomrule
	\end{tabular}
\end{table}


\begin{table}[H]
	\centering
	\caption{Métricas para Ensembles SA (2 modelos): SVM Linear e Regressão Logística (IMDb - Com Pré-Processamento)}
	\begin{tabular}{lcccccc}
		\toprule
		\multirow{2}{*}{\textbf{Modelo}} & \multicolumn{3}{c}{\textbf{Classe Negativa}} & \multicolumn{3}{c}{\textbf{Classe Positiva}} \\
		\cmidrule(lr){2-4} \cmidrule(lr){5-7}
		& \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} \\
		\midrule
		Voting & 0.90 & 0.91 & 0.90 & 0.91 & 0.89 & 0.90 \\
		Stacking & 0.90 & 0.90 & 0.90 & 0.90 & 0.90 & 0.90 \\
		\bottomrule
	\end{tabular}
\end{table}

Nos \textit{ensembles} com 2 modelos, pode-se observar que a combinação foi feita pelos modelos lineares mais fortes, sendo \textit{Regressão Logística}, \textit{SVM Linear} e \textit{SGD}, que apresentaram desempenhos sólidos, tanto no \textit{voting} quanto no \textit{stacking}. No \textit{dataset} do \textit{Letterboxd}, os F1-Scores ficaram entre \textit{0.79} e \textit{0.82}, e na base do \textit{IMDb}, foram alcançados \textit{0.90}. Com este resultado, demonstra-se que, para tarefas de análise de sentimento, um \textit{ensemble} formado por apenas dois modelos fortes pode produzir um desempenho favorável.

\subsection{DESEMPENHO DOS ENSEMBLES COM 3 MODELOS}

\begin{table}[H]
	\centering
	\caption{Métricas para Ensembles SA 3 modelos: Regressão Logística, SVM Linear, SGD(Letterboxd - Com Pré-Processamento)}
	\begin{tabular}{lcccccc}
		\toprule
		\multirow{2}{*}{\textbf{Modelo}} & \multicolumn{3}{c}{\textbf{Classe Negativa}} & \multicolumn{3}{c}{\textbf{Classe Positiva}} \\
		\cmidrule(lr){2-4} \cmidrule(lr){5-7}
		& \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} \\
		\midrule
		Voting & 0.80 & 0.80 & 0.80 & 0.82 & 0.82 & 0.82 \\
		Stacking & 0.80 & 0.80 & 0.80 & 0.82 & 0.82 & 0.82 \\
		\bottomrule
	\end{tabular}
\end{table}

\begin{table}[H]
	\centering
	\caption{Métricas para Ensembles SA 3 modelos: SVM Linear, SGD, Regressão Logística(Letterboxd - Sem Pré-Processamento)}
	\begin{tabular}{lcccccc}
		\toprule
		\multirow{2}{*}{\textbf{Modelo}} & \multicolumn{3}{c}{\textbf{Classe Negativa}} & \multicolumn{3}{c}{\textbf{Classe Positiva}} \\
		\cmidrule(lr){2-4} \cmidrule(lr){5-7}
		& \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} \\
		\midrule
		Voting & 0.79 & 0.80 & 0.79 & 0.82 & 0.82 & 0.82 \\
		Stacking & 0.79 & 0.80 & 0.79 & 0.82 & 0.82 & 0.82 \\
		\bottomrule
	\end{tabular}
\end{table}

\begin{table}[H]
	\centering
	\caption{Métricas para Ensembles SA 3 modelos: SVM Linear, Regressão Logística, SGD (IMDb - Sem Pré-Processamento)}
	\begin{tabular}{lcccccc}
		\toprule
		\multirow{2}{*}{\textbf{Modelo}} & \multicolumn{3}{c}{\textbf{Classe Negativa}} & \multicolumn{3}{c}{\textbf{Classe Positiva}} \\
		\cmidrule(lr){2-4} \cmidrule(lr){5-7}
		& \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} \\
		\midrule
		Voting & 0.90 & 0.90 & 0.90 & 0.90 & 0.90 & 0.90 \\
		Stacking & 0.90 & 0.90 & 0.90 & 0.90 & 0.90 & 0.90 \\
		\bottomrule
	\end{tabular}
\end{table}

\begin{table}[H]
	\centering
	\caption{Métricas para Ensembles SA 3 modelos: SVM Linear, Regressão Logística, SGD (IMDb - Com Pré-Processamento)}
	\begin{tabular}{lcccccc}
		\toprule
		\multirow{2}{*}{\textbf{Modelo}} & \multicolumn{3}{c}{\textbf{Classe Negativa}} & \multicolumn{3}{c}{\textbf{Classe Positiva}} \\
		\cmidrule(lr){2-4} \cmidrule(lr){5-7}
		& \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} \\
		\midrule
		Voting & 0.90 & 0.90 & 0.90 & 0.90 & 0.90 & 0.90 \\
		Stacking & 0.90 & 0.90 & 0.90 & 0.90 & 0.90 & 0.90 \\
		\bottomrule
	\end{tabular}
\end{table}

Nos \textit{ensembles} formados por 3 modelos, com a adição de mais um modelo, que ainda foi um modelo linear, tanto o \textit{voting} quanto o \textit{stacking} mantiveram o desempenho do \textit{ensemble} com dois modelos. Isso mostra que, quando os classificadores são muito parecidos em comportamento e estrutura, os ganhos são limitados.

\subsection{DESEMPENHO DOS ENSEMBLES COM 4 MODELOS}


\begin{table}[H]
	\centering
	\caption{Métricas para Ensembles SA 4 modelos: Regressão Logística, SVM Linear, SGD, Naive Bayes(Letterboxd - Com Pré-Processamento)}
	\begin{tabular}{lcccccc}
		\toprule
		\multirow{2}{*}{\textbf{Modelo}} & \multicolumn{3}{c}{\textbf{Classe Negativa}} & \multicolumn{3}{c}{\textbf{Classe Positiva}} \\
		\cmidrule(lr){2-4} \cmidrule(lr){5-7}
		& \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} \\
		\midrule
		Voting & 0.79 & 0.81 & 0.80 & 0.83 & 0.81 & 0.82 \\
		Stacking & 0.80 & 0.80 & 0.80 & 0.82 & 0.83 & 0.82 \\
		\bottomrule
	\end{tabular}
\end{table}


\begin{table}[H]
	\centering
	\caption{Métricas para Ensembles SA 4 modelos: SVM Linear, SGD, Regressão Logística, LightGBM(Letterboxd - Sem Pré-Processamento)}
	\begin{tabular}{lcccccc}
		\toprule
		\multirow{2}{*}{\textbf{Modelo}} & \multicolumn{3}{c}{\textbf{Classe Negativa}} & \multicolumn{3}{c}{\textbf{Classe Positiva}} \\
		\cmidrule(lr){2-4} \cmidrule(lr){5-7}
		& \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} \\
		\midrule
		Voting & 0.79 & 0.81 & 0.80 & 0.83 & 0.81 & 0.82 \\
		Stacking & 0.79 & 0.80 & 0.80 & 0.83 & 0.81 & 0.82 \\
		\bottomrule
	\end{tabular}
\end{table}


\begin{table}[H]
	\centering
	\caption{Métricas para Ensembles SA 4 modelos: SVM Linear, Regressão Logística, SGD, MLP(IMDb - Sem Pré-Processamento)}
	\begin{tabular}{lcccccc}
		\toprule
		\multirow{2}{*}{\textbf{Modelo}} & \multicolumn{3}{c}{\textbf{Classe Negativa}} & \multicolumn{3}{c}{\textbf{Classe Positiva}} \\
		\cmidrule(lr){2-4} \cmidrule(lr){5-7}
		& \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} \\
		\midrule
		Voting & 0.89 & 0.90 & 0.90 & 0.90 & 0.89 & 0.90 \\
		Stacking & 0.90 & 0.90 & 0.90 & 0.90 & 0.90 & 0.90 \\
		\bottomrule
	\end{tabular}
\end{table}

\begin{table}[H]
	\centering
	\caption{Métricas para Ensembles SA (4 modelos): SVM Linear, Regressão Logística, SGD, MLP(IMDb - Com Pré-Processamento)}
	\begin{tabular}{lcccccc}
		\toprule
		\multirow{2}{*}{\textbf{Modelo}} & \multicolumn{3}{c}{\textbf{Classe Negativa}} & \multicolumn{3}{c}{\textbf{Classe Positiva}} \\
		\cmidrule(lr){2-4} \cmidrule(lr){5-7}
		& \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} \\
		\midrule
		Voting & 0.88 & 0.91 & 0.90 & 0.91 & 0.88 & 0.89 \\
		Stacking & 0.90 & 0.90 & 0.90 & 0.90 & 0.90 & 0.90 \\
		\bottomrule
	\end{tabular}
\end{table}

Com a inclusão de um quarto modelo, puderam ser notados pequenos ganhos de diversidade, principalmente nas bases do \textit{Letterboxd}. A presença de um método diferente (\textit{Naive Bayes} ou \textit{LightGBM}) contribuiu para uma leve melhoria no equilíbrio entre precisão e \textit{recall} em algumas classes; contudo, esses ganhos foram discretos e não superaram de maneira expressiva os \textit{ensembles} com 3 modelos.

\subsection{DESEMPENHO DOS ENSEMBLES COM 5 MODELOS}


\begin{table}[H]
	\centering
	\caption{Métricas para Ensembles SA 5 modelos: Regressão Logística, SVM Linear, SGD, Naive Bayes, MLP(Letterboxd - Com Pré-Processamento)}
	\begin{tabular}{lcccccc}
		\toprule
		\multirow{2}{*}{\textbf{Modelo}} & \multicolumn{3}{c}{\textbf{Classe Negativa}} & \multicolumn{3}{c}{\textbf{Classe Positiva}} \\
		\cmidrule(lr){2-4} \cmidrule(lr){5-7}
		& \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} \\
		\midrule
		Voting & 0.80 & 0.80 & 0.80 & 0.83 & 0.82 & 0.82 \\
		Stacking & 0.80 & 0.81 & 0.80 & 0.83 & 0.82 & 0.83 \\
		\bottomrule
	\end{tabular}
\end{table}


\begin{table}[H]
	\centering
	\caption{Métricas para Ensembles SA 5 modelos: SVM Linear, SGD, Regressão Logística, LightGBM, Naive Bayes(Letterboxd - Sem Pré-Processamento)}
	\begin{tabular}{lcccccc}
		\toprule
		\multirow{2}{*}{\textbf{Modelo}} & \multicolumn{3}{c}{\textbf{Classe Negativa}} & \multicolumn{3}{c}{\textbf{Classe Positiva}} \\
		\cmidrule(lr){2-4} \cmidrule(lr){5-7}
		& \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} \\
		\midrule
		Voting & 0.79 & 0.80 & 0.79 & 0.82 & 0.82 & 0.82 \\
		Stacking & 0.79 & 0.81 & 0.80 & 0.83 & 0.81 & 0.82 \\
		\bottomrule
	\end{tabular}
\end{table}


\begin{table}[H]
	\centering
	\caption{Métricas para Ensembles SA 5 modelos: Linear SVM, Regressão Logística, SGD, MLP, LightGBM(IMDb - Sem Pré-Processamento)}
	\begin{tabular}{lcccccc}
		\toprule
		\multirow{2}{*}{\textbf{Modelo}} & \multicolumn{3}{c}{\textbf{Classe Negativa}} & \multicolumn{3}{c}{\textbf{Classe Positiva}} \\
		\cmidrule(lr){2-4} \cmidrule(lr){5-7}
		& \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} \\
		\midrule
		Voting & 0.90 & 0.89 & 0.90 & 0.89 & 0.90 & 0.90 \\
		Stacking & 0.90 & 0.89 & 0.90 & 0.89 & 0.90 & 0.90 \\
		\bottomrule
	\end{tabular}
\end{table}

\begin{table}[H]
	\centering
	\caption{Métricas para Ensembles SA 5 modelos: SVM Linear, Regressão Logística, SGD, MLP, LightGBM(IMDb - Sem Pré-Processamento)}
	\begin{tabular}{lcccccc}
		\toprule
		\multirow{2}{*}{\textbf{Modelo}} & \multicolumn{3}{c}{\textbf{Classe Negativa}} & \multicolumn{3}{c}{\textbf{Classe Positiva}} \\
		\cmidrule(lr){2-4} \cmidrule(lr){5-7}
		& \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} \\
		\midrule
		Voting & 0.90 & 0.90 & 0.90 & 0.90 & 0.90 & 0.90 \\
		Stacking & 0.90 & 0.90 & 0.90 & 0.90 & 0.90 & 0.90 \\
		\bottomrule
	\end{tabular}
\end{table}

Por fim, nos \textit{ensembles} com 5 modelos, com a adição de outro modelo de natureza diferente (\textit{MLP} e \textit{Naive Bayes}), foi observado um comportamento mais consistente na base do \textit{Letterboxd} e estabilidade completa nas bases do \textit{IMDb}. O \textit{voting} e o \textit{stacking} produziram resultados praticamente equivalentes, com F1-Scores variando entre \textit{0.80} e \textit{0.83} no \textit{Letterboxd} e atingindo \textit{0.90} no \textit{IMDb}. Esses resultados demonstram que a adição de diversidade ao conjunto, mesmo que de maneira moderada, pode trazer equilíbrio às métricas de avaliação, mas não resultará em um grande ganho, visto que \textit{ensembles} menores já continham modelos muito consistentes e dominantes.

No geral, a técnica de \textit{SA} confirma que \textit{ensembles} pequenos, formados por modelos com alta acurácia, já são capazes de apresentar um desempenho favorável e comparável aos \textit{ensembles} maiores. No entanto, o ganho principal está no tempo de treinamento, pois \textit{ensembles} com menos modelos treinam mais rapidamente e mantêm métricas competitivas. Os resultados reforçam a força dos modelos lineares na análise de sentimento.

\section{SELEÇÃO POR ACURÁCIA E DIVERSIDADE}

Na abordagem \textit{SAD} (Seleção por Acurácia e Diversidade), temos a combinação de dois critérios: o desempenho individual dos modelos e o grau de diversidade entre as suas previsões. Essa técnica de seleção tem como objetivo escolher subconjuntos de classificadores que sejam tanto \textit{competentes quanto diversos}. Modelos com maior diversidade podem reduzir a variância e os vieses por oferecerem perspectivas diferentes sobre os dados, já que seu funcionamento é distinto. Logo, nesta seção, serão discutidos e apresentados os resultados dos \textit{ensembles} formados por 2, 3, 4 e 5 modelos selecionados pelo método \textit{SAD}.


\subsection{DESEMPENHO DOS ENSEMBLES COM 2 MODELOS}

\begin{table}[H]
	\centering
	\caption{Métricas para Ensembles SAD 2 modelos: RandomForest, KNN (Letterboxd - Com Pré-Processamento)}
	\begin{tabular}{lcccccc}
		\toprule
		\multirow{2}{*}{\textbf{Modelo}} & \multicolumn{3}{c}{\textbf{Classe Negativa}} & \multicolumn{3}{c}{\textbf{Classe Positiva}} \\
		\cmidrule(lr){2-4} \cmidrule(lr){5-7}
		& \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} \\
		\midrule
		Voting & 0.56 & 0.91 & 0.69 & 0.82 & 0.37 & 0.51 \\
		Stacking & 0.75 & 0.79 & 0.77 & 0.80 & 0.77 & 0.79 \\
		\bottomrule
	\end{tabular}
\end{table}

\begin{table}[H]
	\centering
	\caption{Métricas para Ensembles SAD 2 modelos: Random Forest e KNN (Letterboxd - Sem Pré-Processamento)}
	\begin{tabular}{lcccccc}
		\toprule
		\multirow{2}{*}{\textbf{Modelo}} & \multicolumn{3}{c}{\textbf{Classe Negativa}} & \multicolumn{3}{c}{\textbf{Classe Positiva}} \\
		\cmidrule(lr){2-4} \cmidrule(lr){5-7}
		& \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} \\
		\midrule
		Voting & 0.57 & 0.88 & 0.69 & 0.79 & 0.42 & 0.55 \\
		Stacking & 0.75 & 0.77 & 0.76 & 0.79 & 0.77 & 0.78 \\
		\bottomrule
	\end{tabular}
\end{table}

\begin{table}[H]
	\centering
	\caption{Métricas para Ensembles SAD 2 modelos: KNN e MLP(IMDb - Sem Pré-Processamento)}
	\begin{tabular}{lcccccc}
		\toprule
		\multirow{2}{*}{\textbf{Modelo}} & \multicolumn{3}{c}{\textbf{Classe Negativa}} & \multicolumn{3}{c}{\textbf{Classe Positiva}} \\
		\cmidrule(lr){2-4} \cmidrule(lr){5-7}
		& \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} \\
		\midrule
		Voting & 0.74 & 0.93 & 0.82 & 0.91 & 0.67 & 0.77 \\
		Stacking & 0.87 & 0.88 & 0.87 & 0.87 & 0.87 & 0.87 \\
		\bottomrule
	\end{tabular}
\end{table}


\begin{table}[H]
	\centering
	\caption{Métricas para Ensembles SAD (2 modelos): MLP e LightGBM(IMDb - Com Pré-Processamento)}
	\begin{tabular}{lcccccc}
		\toprule
		\multirow{2}{*}{\textbf{Modelo}} & \multicolumn{3}{c}{\textbf{Classe Negativa}} & \multicolumn{3}{c}{\textbf{Classe Positiva}} \\
		\cmidrule(lr){2-4} \cmidrule(lr){5-7}
		& \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} \\
		\midrule
		Voting & 0.84 & 0.93 & 0.89 & 0.93 & 0.83 & 0.87 \\
		Stacking & 0.90 & 0.90 & 0.90 & 0.90 & 0.90 & 0.90 \\
		\bottomrule
	\end{tabular}
\end{table}


Nos \textit{ensembles} com 2 modelos, pode-se observar como o método \textit{SAD} já performa, selecionando modelos estruturalmente diferentes, como o \textit{Random Forest} e \textit{KNN} na base \textit{Letterboxd} ou \textit{MLP} e \textit{LightGBM} na base \textit{IMDb}. Essa seleção demonstra o papel da \textit{diversidade}: mesmo quando o desempenho individual de alguns desses modelos não está entre os melhores, a combinação pode gerar \textit{ensembles} mais equilibrados. No entanto, os ganhos não ocorrem em todos os casos. Na base \textit{Letterboxd}, especialmente na versão com pré-processamento, o \textit{Voting} apresentou um forte desequilíbrio entre as classes, enquanto o \textit{Stacking}, por ser mais robusto funcionando com um meta-aprendiz, exibiu resultados superiores e muito mais estáveis, alcançando F1-Scores próximos de \textit{0.79} e \textit{0.77} para as duas versões da base. Na base \textit{IMDb}, o impacto da diversidade foi mais consistente: pares como \textit{MLP–KNN} ou \textit{MLP–LightGBM} produziram \textit{ensembles} com F1-Scores entre \textit{0.87} e \textit{0.90}, destacando o potencial da técnica em bases mais robustas.


\subsection{DESEMPENHO DOS ENSEMBLES COM 3 MODELOS}


\begin{table}[H]
	\centering
	\caption{Métricas para Ensembles SAD 3 modelos: MLP, RandomForest, KNN(Letterboxd - Com Pré-Processamento)}
	\begin{tabular}{lcccccc}
		\toprule
		\multirow{2}{*}{\textbf{Modelo}} & \multicolumn{3}{c}{\textbf{Classe Negativa}} & \multicolumn{3}{c}{\textbf{Classe Positiva}} \\
		\cmidrule(lr){2-4} \cmidrule(lr){5-7}
		& \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} \\
		\midrule
		Voting & 0.76 & 0.81 & 0.79 & 0.82 & 0.78 & 0.80 \\
		Stacking & 0.78 & 0.82 & 0.80 & 0.83 & 0.80 & 0.82 \\
		\bottomrule
	\end{tabular}
\end{table}


\begin{table}[H]
	\centering
	\caption{Métricas para Ensembles SAD 3 modelos: KNN, Random Forest, AdaBoost(Letterboxd - Sem Pré-Processamento)}
	\begin{tabular}{lcccccc}
		\toprule
		\multirow{2}{*}{\textbf{Modelo}} & \multicolumn{3}{c}{\textbf{Classe Negativa}} & \multicolumn{3}{c}{\textbf{Classe Positiva}} \\
		\cmidrule(lr){2-4} \cmidrule(lr){5-7}
		& \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} \\
		\midrule
		Voting & 0.76 & 0.76 & 0.76 & 0.79 & 0.79 & 0.79 \\
		Stacking & 0.75 & 0.77 & 0.76 & 0.79 & 0.77 & 0.78 \\
		\bottomrule
	\end{tabular}
\end{table}

\begin{table}[H]
	\centering
	\caption{Métricas para Ensembles SAD 3 modelos: MLP, Random Forest, KNN(IMDb - Sem Pré-Processamento)}
	\begin{tabular}{lcccccc}
		\toprule
		\multirow{2}{*}{\textbf{Modelo}} & \multicolumn{3}{c}{\textbf{Classe Negativa}} & \multicolumn{3}{c}{\textbf{Classe Positiva}} \\
		\cmidrule(lr){2-4} \cmidrule(lr){5-7}
		& \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} \\
		\midrule
		Voting & 0.88 & 0.85 & 0.86 & 0.86 & 0.88 & 0.87 \\
		Stacking & 0.89 & 0.88 & 0.89 & 0.88 & 0.89 & 0.89 \\
		\bottomrule
	\end{tabular}
\end{table}

\begin{table}[H]
	\centering
	\caption{Métricas para Ensembles SAD 3 modelos: LightGBM, RandomForest, MLP(IMDb - Com Pré-Processamento)}
	\begin{tabular}{lcccccc}
		\toprule
		\multirow{2}{*}{\textbf{Modelo}} & \multicolumn{3}{c}{\textbf{Classe Negativa}} & \multicolumn{3}{c}{\textbf{Classe Positiva}} \\
		\cmidrule(lr){2-4} \cmidrule(lr){5-7}
		& \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} \\
		\midrule
		Voting & 0.90 & 0.87 & 0.89 & 0.88 & 0.90 & 0.89 \\
		Stacking & 0.90 & 0.90 & 0.90 & 0.90 & 0.90 & 0.90 \\
		\bottomrule
	\end{tabular}
\end{table}

Adicionando mais um modelo, pôde-se perceber um comportamento mais sólido nos \textit{ensembles}, tanto no \textit{Voting} quanto no \textit{Stacking}. A inclusão de um terceiro classificador aumentou a capacidade de equilíbrio entre a precisão e o \textit{recall}, principalmente na base do \textit{Letterboxd}. No cenário pré-processado, o \textit{ensemble} formado por \textit{MLP}, \textit{Random Forest} e \textit{KNN} apresentou F1-Scores entre \textit{0.79} e \textit{0.82}, enquanto na versão sem pré-processamento os resultados permaneceram próximos, mas com menos estabilidade. Na base \textit{IMDb}, os modelos escolhidos pelo \textit{SAD} (\textit{MLP}, \textit{Random Forest} e \textit{KNN}, ou \textit{LightGBM}, \textit{MLP} e \textit{Random Forest}) alcançaram um desempenho consistentemente alto, chegando a F1-Scores de \textit{0.89} para \textit{voting} e \textit{0.90} para \textit{stacking}. Isso mostra que, ao contrário da seleção apenas por acurácia, a seleção por acurácia e diversidade tende a produzir benefícios quando combina modelos de naturezas distintas.

\subsection{DESEMPENHO DOS ENSEMBLES COM 4 MODELOS}


\begin{table}[H]
	\centering
	\caption{Métricas para Ensembles SAD 4 modelos: Regressão Logística, RandomForest, LightGBM, MLP(Letterboxd - Com Pré-Processamento)}
	\begin{tabular}{lcccccc}
		\toprule
		\multirow{2}{*}{\textbf{Modelo}} & \multicolumn{3}{c}{\textbf{Classe Negativa}} & \multicolumn{3}{c}{\textbf{Classe Positiva}} \\
		\cmidrule(lr){2-4} \cmidrule(lr){5-7}
		& \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} \\
		\midrule
		Voting & 0.77 & 0.84 & 0.80 & 0.85 & 0.78 & 0.81 \\
		Stacking & 0.80 & 0.81 & 0.80 & 0.83 & 0.82 & 0.82 \\
		\bottomrule
	\end{tabular}
\end{table}

\begin{table}[H]
	\centering
	\caption{Métricas para Ensembles SAD 4 modelos: KNN, Naive Bayes, AdaBoost, Decision Tree(Letterboxd - Sem Pré-Processamento)}
	\begin{tabular}{lcccccc}
		\toprule
		\multirow{2}{*}{\textbf{Modelo}} & \multicolumn{3}{c}{\textbf{Classe Negativa}} & \multicolumn{3}{c}{\textbf{Classe Positiva}} \\
		\cmidrule(lr){2-4} \cmidrule(lr){5-7}
		& \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} \\
		\midrule
		Voting & 0.73 & 0.82 & 0.77 & 0.82 & 0.73 & 0.78 \\
		Stacking & 0.79 & 0.77 & 0.78 & 0.80 & 0.82 & 0.81 \\
		\bottomrule
	\end{tabular}
\end{table}

\begin{table}[H]
	\centering
	\caption{Métricas para Ensembles SAD 4 modelos: MLP, Linear SVM, Naive Bayes, Regressão Logística(IMDb - Sem Pré-Processamento)}
	\begin{tabular}{lcccccc}
		\toprule
		\multirow{2}{*}{\textbf{Modelo}} & \multicolumn{3}{c}{\textbf{Classe Negativa}} & \multicolumn{3}{c}{\textbf{Classe Positiva}} \\
		\cmidrule(lr){2-4} \cmidrule(lr){5-7}
		& \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} \\
		\midrule
		Voting & 0.89 & 0.90 & 0.90 & 0.90 & 0.88 & 0.89 \\
		Stacking & 0.89 & 0.90 & 0.90 & 0.90 & 0.89 & 0.90 \\
		\bottomrule
	\end{tabular}
\end{table}


\begin{table}[H]
	\centering
	\caption{Métricas para Ensembles SAD 4 modelos: Regressão Logística, KNN, AdaBoost, RandomForest(IMDb - Com Pré-Processamento)}
	\begin{tabular}{lcccccc}
		\toprule
		\multirow{2}{*}{\textbf{Modelo}} & \multicolumn{3}{c}{\textbf{Classe Negativa}} & \multicolumn{3}{c}{\textbf{Classe Positiva}} \\
		\cmidrule(lr){2-4} \cmidrule(lr){5-7}
		& \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} \\
		\midrule
		Voting & 0.88 & 0.90 & 0.89 & 0.90 & 0.87 & 0.89 \\
		Stacking & 0.90 & 0.90 & 0.90 & 0.90 & 0.90 & 0.90 \\
		\bottomrule
	\end{tabular}
\end{table}


Nos \textit{ensembles} compostos por 4 modelos, a técnica \textit{SAD} demonstrou maior capacidade de explorar diversidade, montando um classificador que combinava diversos tipos de classificadores, como modelos lineares, modelos baseados em árvores, redes neurais e algoritmos \textit{instance-based}. Os resultados da base de dados \textit{Letterboxd} indicaram um aumento na estabilidade, com F1-Scores entre \textit{0.80} e \textit{0.82} para \textit{voting} e \textit{stacking}. Na versão sem pré-processamento, o conjunto mais diverso, incluindo \textit{KNN}, \textit{Naive Bayes}, \textit{AdaBoost} e \textit{Decision Tree}, mostrou que essa heterogeneidade pode compensar fraquezas individuais. Já no \textit{IMDb}, tanto com como sem pré-processamento, os resultados permaneceram elevados, com F1-Scores entre \textit{0.89} e \textit{0.90}, com o \textit{Stacking} atingindo \textit{0.90} em todos os cenários. Isso reforça que \textit{ensembles} moderadamente grandes e diversificados conseguem capturar diferentes aspectos dos dados sem reduzir a consistência geral.


\subsection{DESEMPENHO DOS ENSEMBLES COM 5 MODELOS}


\begin{table}[H]
	\centering
	\caption{Métricas para Ensembles SAD 5 modelos: Regressão Logística, RandomForest, LightGBM, MLP, KNN(Letterboxd - Com Pré-Processamento)}
	\begin{tabular}{lcccccc}
		\toprule
		\multirow{2}{*}{\textbf{Modelo}} & \multicolumn{3}{c}{\textbf{Classe Negativa}} & \multicolumn{3}{c}{\textbf{Classe Positiva}} \\
		\cmidrule(lr){2-4} \cmidrule(lr){5-7}
		& \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} \\
		\midrule
		Voting & 0.79 & 0.81 & 0.80 & 0.83 & 0.81 & 0.82 \\
		Stacking & 0.80 & 0.81 & 0.81 & 0.83 & 0.82 & 0.83 \\
		\bottomrule
	\end{tabular}
\end{table}






\begin{table}[H]
	\centering
	\caption{Métricas Consolidadas para Ensembles SAD 5 modelos: KNN, Naive Bayes, AdaBoost, Decision Tree, LightGBM(Letterboxd - Sem Pré-Processamento)}
	\begin{tabular}{lcccccc}
		\toprule
		\multirow{2}{*}{\textbf{Modelo}} & \multicolumn{3}{c}{\textbf{Classe Negativa}} & \multicolumn{3}{c}{\textbf{Classe Positiva}} \\
		\cmidrule(lr){2-4} \cmidrule(lr){5-7}
		& \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} \\
		\midrule
		Voting & 0.78 & 0.77 & 0.78 & 0.80 & 0.81 & 0.80 \\
		Stacking & 0.80 & 0.79 & 0.79 & 0.81 & 0.82 & 0.82 \\
		\bottomrule
	\end{tabular}
\end{table}






\begin{table}[H]
	\centering
	\caption{Métricas para Ensembles SAD 5 modelos: MLP, Linear SVM, Naive Bayes, Regressão Logística, KNN(IMDb - Sem Pré-Processamento)}
	\begin{tabular}{lcccccc}
		\toprule
		\multirow{2}{*}{\textbf{Modelo}} & \multicolumn{3}{c}{\textbf{Classe Negativa}} & \multicolumn{3}{c}{\textbf{Classe Positiva}} \\
		\cmidrule(lr){2-4} \cmidrule(lr){5-7}
		& \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} \\
		\midrule
		Voting & 0.90 & 0.89 & 0.90 & 0.89 & 0.90 & 0.90 \\
		Stacking & 0.89 & 0.90 & 0.90 & 0.90 & 0.89 & 0.90 \\
		\bottomrule
	\end{tabular}
\end{table}






\begin{table}[H]
	\centering
	\caption{Métricas para Ensembles SAD 5 modelos: Regressão Logística, KNN, AdaBoost, RandomForest, MLP(IMDb - Com Pré-Processamento)}
	\begin{tabular}{lcccccc}
		\toprule
		\multirow{2}{*}{\textbf{Modelo}} & \multicolumn{3}{c}{\textbf{Classe Negativa}} & \multicolumn{3}{c}{\textbf{Classe Positiva}} \\
		\cmidrule(lr){2-4} \cmidrule(lr){5-7}
		& \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Precisão} & \textbf{Recall} & \textbf{F1-Score} \\
		\midrule
		Voting & 0.91 & 0.88 & 0.90 & 0.89 & 0.91 & 0.90 \\
		Stacking & 0.90 & 0.90 & 0.90 & 0.90 & 0.90 & 0.90 \\
		\bottomrule
	\end{tabular}
\end{table}

Com 5 modelos formando o \textit{ensemble}, estes foram os que mais demonstraram estabilidade dentro da abordagem \textit{SAD}. Na base do \textit{Letterboxd}, tanto com pré-processamento quanto sem, o \textit{voting} e o \textit{stacking} alcançaram F1-Scores entre \textit{0.79} e \textit{0.83}, mostrando ganhos de robustez conforme mais modelos diversos eram incluídos. Na base do \textit{IMDb}, os \textit{ensembles} apresentaram excelentes desempenhos, com F1-Scores de aproximadamente \textit{0.90} em todos os cenários, tanto no \textit{voting} quanto no \textit{stacking}. Com isso, pode-se notar que \textit{ensembles} compostos por combinações de modelos lineares, redes neurais e modelos de árvores, como o conjunto \textit{Regressão Logística}, \textit{KNN}, \textit{AdaBoost}, \textit{Random Forest} e \textit{MLP}, demonstraram ser equilibrados entre os valores de precisão e \textit{recall} nas duas classes.

Os resultados do \textit{SAD} mostram que a combinação entre acurácia e diversidade permite selecionar subconjuntos de modelos que são capazes de alcançar desempenho elevado mesmo com a inclusão de classificadores com desempenho individual inferior. A técnica se mostrou eficaz quando os \textit{ensembles} eram formados por 3 ou mais modelos e teve um melhor desempenho quando aplicada à base de dados do \textit{IMDb}. Com isso, podemos concluir que a diversidade desempenha um papel importante e fundamental para melhorar a estabilidade, compensar vieses e aumentar a robustez no contexto da análise de sentimentos.

A comparação entre os três tipos de seleção e as técnicas de \textit{ensemble} mostram diferenças importantes na forma como cada estratégia reage às características das bases de dados e das técnicas de pré-processamento. Os \textit{ensembles} sem seleção, formados por todos os 10 modelos, apresentaram um \textit{desempenho sólido} em todos os cenários. A grande \textit{diversidade estrutural} tornou esse \textit{ensemble} bastante robusto, o que resultou em métricas estáveis, principalmente na base do \textit{IMDb}, onde os F1-Scores ficaram em torno de \textit{0.90}. Entretanto, para o \textit{Voting}, a inclusão de tantos modelos fracos não foi benéfica, resultando em um aumento do custo computacional e do tempo de treinamento.


A seleção por acurácia (\textit{SA}) mostrou um comportamento que já era esperado e eficiente, pois priorizou os modelos de melhor desempenho individual, principalmente os \textit{modelos lineares}, como \textit{SVM Linear}, \textit{Regressão Logística} e \textit{SGD}. Nesse cenário, os \textit{ensembles} tornaram-se eficazes com poucos modelos em sua composição (a partir de 3), o que os torna mais rápidos no treinamento que os \textit{ensembles} maiores. Os \textit{ensembles} com 3 modelos já produziam resultados idênticos aos modelos com 4 e 5. Esses \textit{ensembles} pequenos, dominados por modelos lineares, especialmente na base de dados \textit{IMDb}, dominaram o problema de classificação.

Já na seleção por acurácia e diversidade (\textit{SAD}), os resultados tiveram padrões distintos. Modelos com desempenho mais modestos passaram a compor o \textit{ensemble}, aumentando a diversidade e complementando as previsões. Contudo, isso resultou em um \textit{Voting} menos estável, especialmente na base de dados do \textit{Letterboxd}, onde diferenças muito grandes entre os classificadores geraram decisões conflitantes. No entanto, com o \textit{Stacking}, essa diversidade foi uma vantagem que superou o \textit{Voting} em praticamente todos os cenários e aproximou-se dos melhores resultados obtidos pela \textit{SA}. Em bases com mais ruído, como a do \textit{Letterboxd}, a diversidade contribuiu para o equilíbrio entre precisão e \textit{recall}.

